---
layout: page
title: "Text Generation"
permalink: /docs/text-gen
parent:  "Serverless Cloud API - Dataoorts AI"
nav_order: 3
has_childrens: true
---

# {{page.title}}

<div style="font-size:0.78em;color: #797878; margin-bottom:1.5em;">
     <span>11 Articles</span>
</div>


## [deepseek-ai/deepseek-r1-distill-qwen-32b](/docs/deepseek-aideepseek-r1-distill-qwen-32b/)
The DeepSeek-R1-Distill-Qwen-32B model, distilled from DeepSeek-R1 using Qwen2.5, surpasses o1-mini in multiple benchmarks and sets new state-of-the-art performance standards for dense models. Get Your API Credential From: https://cloud.data...

## [deepseek-ai/deepseek-math-7b-instruct](/docs/deepseek-aideepseek-math-7b-instruct/)
DeepSeekMath-Instruct 7B is a fine-tuned mathematical model based on DeepSeekMath-Base 7B. It originates from DeepSeek-Coder-v1.5 7B and undergoes additional pre-training on 500B tokens, incorporating math-related data from Common Crawl, as well as ...

## [google/gemma-3-12b-it](/docs/googlegemma-3-12b-it/)
The Gemma 3 series excels across a wide range of text-generation and image-comprehension tasks—such as question‑answering, summarization, and logical reasoning. These multimodal models accept both text and image inputs and produce text outputs. They...

## [meta/llama-4-scout-17b-16e-instruct](/docs/meta-4/)
Meta’s Llama 4 Scout is a native multimodal model featuring a 17-billion‑parameter "active" layer, supported by 16 experts, and built on a mixture‑of‑experts architecture. It delivers state‑of‑the‑art performance in both text and image understanding...
 
## [meta/llama-3.3-70b-instruct-fp8-fast](/docs/metallama-3.3-70b-instruct-fp8-fast)
Llama 3.3 70B has been quantized to FP8 precision, enhancing its optimization for improved speed. Get Your API Credential From: https://cloud.dataoorts.com/ai import requests import json # Define the endpoint URL url = 'https://cloud.d...
 
## [meta/llama-3.1-70b-instruct](/docs/metallama-3.1-70b-instruct/)
The Meta Llama 3.1 series comprises multilingual large language models that are both pretrained and instruction-tuned for generative tasks. The text-only instruction-tuned models in the Llama 3.1 collection are specifically optimized for multilingua...

## [meta/llama-3.1-8b-instruct](/docs/metallama-3.1-8b-instruct/)
The Meta Llama 3.1 8B series consists of multilingual large language models that are both pretrained and instruction-tuned for generative tasks. These text-only instruction-tuned models are specifically designed for multilingual dialogue scenarios a...

## [meta/llama-guard-3-8b](/docs/metallama-guard-3-8b/)
Llama Guard 3, based on the Llama-3.1-8B pretrained model, is fine-tuned specifically for content safety classification. Like its earlier versions, it is designed to classify content within both LLM inputs (prompt classification) and outputs (respon...

## [qwen/qwq-32b](/docs/qwenqwen-32b/)
QwQ is the dedicated reasoning model within Alibaba’s Qwen family. Unlike standard instruction-tuned models, QwQ is built to think and reason, delivering superior performance on challenging tasks. In particular, QwQ‑32B, the mid‑sized variant with a...

## [qwen/qwen2.5-coder-32b-instruct](/docs/qweb-coder/)
Qwen2.5‑Coder is the newest code‑specialized entry in the Qwen model family (formerly known as CodeQwen), now available in six sizes—0.5B, 1.5B, 3B, 7B, 14B, and 32B parameters—to cater to developers with diverse requirements. Building on the founda...
 
## [qwen/qwen1.5-14b-chat-awq](/docs/qwenqwen1.5-1.4b-chat-awq/)
Qwen1.5 is an enhanced iteration of Qwen, the large language model series created by Alibaba Cloud. AWQ is a highly efficient, precise, and ultra-fast low-bit weight quantization technique, currently supporting 4-bit quantization. Get Your AP...
